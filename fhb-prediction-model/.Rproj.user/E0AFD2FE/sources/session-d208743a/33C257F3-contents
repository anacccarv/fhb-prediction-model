---
title: "modelo_05_2025"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# Bibliotecas

```{r}
library(tidyverse)
library(purrr)
library(gsheet)
library(raster)
library(ncdf4)
library(lubridate)
library(readxl)
library(writexl)
library(caret)
library(tidyr)
#library(r4pde)
library(refund)
library(readr)
library(fdatest)
library(dplyr)
library(rlang)
library(rms)
library(pROC)
library(PresenceAbsence)
library(OptimalCutpoints)
library(ggtext)
library(scales)
library(PRROC)
library(patchwork)
```

# Data

```{r}
data <- read_xlsx("plan/weather_data_final.xlsx")


data <- data %>%
  filter(!study %in% 126:150)

data <- data |> 
    mutate(
    e_s = 0.6108 * exp((17.27 * T2M) / (T2M + 237.3)),
    e_a = e_s * (RH2M / 100),
    VPD = e_s - e_a)

```

# Nasa power

```{r}

# data1 <- data |> 
#   group_by(study) |> 
#   slice(1) |> 
#   select(study, flowering, lat, lon) |> 
#   rename(latitude = lat, longitude = lon)
# 
# trials <- data1 |> 
#   select(study, flowering)
# 
# weather_data <- r4pde::get_nasapower(
#    data = data1,
#    days_around = 28,
#     date_col = "flowering",
#    pars = c("GWETROOT", "GWETTOP", "T2M", "T2M_MAX", "T2M_MIN", "T2M_RANGE", "RH2M", "PRECTOTCORR", "T2MDEW","WS2M", "PS", "ALLSKY_SFC_SW_DWN", "CLRSKY_SFC_SW_DWN"))
# 
# data_nasa <- left_join(trials, weather_data)
# 
# epidemic <- data |> 
#   group_by(study) |> 
#   slice(1) |> 
#   select(epidemic)
# 
# 
# data_nasa <- data_nasa |> 
#  mutate(days = as.numeric(YYYYMMDD - as.Date(flowering))) |> 
#   left_join(epidemic) |> 
#   mutate(TDD = T2M_MIN - T2MDEW)

# write_csv(data_nasa, "plan/weather_data_nasa.csv")

data_nasa <- read_csv("plan/weather_data_nasa.csv")

```

# FDA

## Interval test procedure

```{r}

# função 1
fda_itp_test <- function(data, variable, epidemic_col = "epidemic", day_col = "days", study_col = "study", B = 100, xrange = c(-28, 28)) {
  
  
  # Prepare epidemic and non-epidemic data
  df_epi <- data %>%
    filter(.data[[epidemic_col]] == 1) %>%
    dplyr::select(all_of(c(variable, day_col, study_col)))
  
  df_nonepi <- data %>%
    filter(.data[[epidemic_col]] == 0) %>%
    dplyr::select(all_of(c(variable, day_col, study_col)))
  
  # Pivot to wide
  df_epi_wide <- df_epi %>%
    group_by(across(all_of(study_col))) %>%
    pivot_wider(names_from = all_of(day_col), values_from = all_of(variable)) %>%
    ungroup() %>%
    dplyr::select(-all_of(study_col))
  
  df_nonepi_wide <- df_nonepi %>%
    group_by(across(all_of(study_col))) %>%
    pivot_wider(names_from = all_of(day_col), values_from = all_of(variable)) %>%
    ungroup() %>%
    dplyr::select(-all_of(study_col))
  
  # Convert to matrices
  mat_epi <- as.matrix(df_epi_wide)
  mat_nonepi <- as.matrix(df_nonepi_wide)
  
  # Perform ITP test
  itp_result <- ITP2bspline(data1 = mat_epi, data2 = mat_nonepi, B = B)
  
  # Plot result
  plot(itp_result, main = variable, xrange = xrange, xlab = 'Day', xaxt = 'n')
  axis(1, at = seq(xrange[1], xrange[2], by = 2), labels = seq(xrange[1], xrange[2], by = 2))
  
  return(itp_result)
}


# Função 2
run_ITP_test <- function(data, weather_var = "RH2M", B = 100) {
  

  
  weather_var_sym <- sym(weather_var)
  
  # Filter epidemic data
  df_epidemic <- data %>%
    mutate(days = round(days)) %>%
    filter(epidemic == 1, days > -90) %>%
    dplyr::select(!!weather_var_sym, days, study) %>%
    group_by(study, days) %>%
    summarise(value = mean(!!weather_var_sym, na.rm = TRUE), .groups = "drop")
  
  # Filter non-epidemic data
  df_non_epidemic <- data %>%
    mutate(days = round(days)) %>%
    filter(epidemic != 1, days > -90) %>%
    dplyr::select(!!weather_var_sym, days, study) %>%
    group_by(study, days) %>%
    summarise(value = mean(!!weather_var_sym, na.rm = TRUE), .groups = "drop")
  
  # Pivot to wide format
  df_epidemic_wide <- df_epidemic %>%
    pivot_wider(names_from = days, values_from = value) %>%
    ungroup() %>%
    dplyr::select(-study)
  
  df_non_epidemic_wide <- df_non_epidemic %>%
    pivot_wider(names_from = days, values_from = value) %>%
    ungroup() %>%
    dplyr::select(-study)
  
 
  
  # Convert to matrix
  data_epidemic <- as.matrix(df_epidemic_wide)
  data_non_epidemic <- as.matrix(df_non_epidemic_wide)
  
  # Perform FDA test
  itp_result <- ITP2bspline(data1 = data_epidemic, data2 = data_non_epidemic, B = B)
  
  # Output results
  cat("Global p-value for", weather_var, ":", itp_result$corrected.pval, "\n")
  significant_components <- which(itp_result$corrected.pval < 0.05)
  
  if (length(significant_components) > 0) {
    cat("Significant components (basis coefficients) for", weather_var, ":\n")
    print(significant_components)
  } else {
    cat("No significant components found for", weather_var, "\n")
  }
  
  # Plot FDA results
  plot(itp_result, main = weather_var, xrange = c(-28, 28), xlab = 'Day', xaxt = 'n')
  axis(1, at = seq(-28, 28, by = 2), labels = seq(-28, 28, by = 2))
  pvals <- itp_result$pval

  # Define significance threshold
  alpha <- 0.05

  # Identify significant time points
  significant_points <- which(pvals < alpha)

  # Group into contiguous regions
  if (length(significant_points) > 0) {
    stable_regions <- split(significant_points, cumsum(c(1, diff(significant_points) != 1)))
    region_ranges <- lapply(stable_regions, function(x) range(x))

    cat("Stable regions (p-value <", alpha, "):\n")
    for (r in region_ranges) {
      cat("Day", r[1] - 28, "to", r[2] - 28, "\n")
    }
  } else {
    cat("No stable regions with p-value <", alpha, " found.\n")
  }
  
  return(itp_result)
}
```

### T2M_MIN

```{r}


result_tmin <- fda_itp_test(data = data, variable = "T2M_MIN")
result_tmin$corrected.pval
which(result_tmin$corrected.pval < 0.05)


itp_tmin <- run_ITP_test(data = data, weather_var = "T2M_MIN", B = 100)
itp_tmin
```

### RH2M

```{r}
result_rh <- fda_itp_test(data = data, variable = "RH2M")
result_rh$corrected.pval
which(result_rh$corrected.pval < 0.05)



itp_rh <- run_ITP_test(data = data, weather_var = "RH2M", B = 100)
itp_rh
```

### RH2M NASA

```{r}
result_rh <- fda_itp_test(data = data_nasa, variable = "RH2M")
result_rh$corrected.pval
which(result_rh$corrected.pval < 0.05)

itp_rh <- run_ITP_test(data = data_nasa, weather_var = "RH2M", B = 100)
itp_rh
```

### PRECTOTCORR

```{r}
result_prec <- fda_itp_test(data = data, variable = "PRECTOTCORR")
result_prec$corrected.pval
which(result_prec$corrected.pval < 0.05)

itp_prec <- run_ITP_test(data = data, weather_var = "PRECTOTCORR", B = 100)
itp_prec
```

### PRECTOTCORR NASA

```{r}
result_prec <- fda_itp_test(data = data_nasa, variable = "PRECTOTCORR")
result_prec$corrected.pval
which(result_prec$corrected.pval < 0.05)
```

### VPD

```{r}
result_prec <- fda_itp_test(data = data, variable = "VPD")
result_prec$corrected.pval
which(result_prec$corrected.pval < 0.05)
```

### GWETTOP

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "GWETTOP")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

### ALLSKY_SFC_SW_DWN

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "ALLSKY_SFC_SW_DWN")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

### TDD

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "TDD")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

### WS2M

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "WS2M")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

### T2M_RANGE

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "T2M_RANGE")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

### T2MDEW

```{r}
result_gwettop <- fda_itp_test(data = data_nasa, variable = "T2MDEW")
result_gwettop$corrected.pval
which(result_gwettop$corrected.pval < 0.05)
```

## Create predictors

```{r}
process_weather_var <- function(data, var_name, days_range, new_col_name, summary_func = c("mean", "sum")) {
  summary_func <- match.arg(summary_func)
  day_cols <- as.character(days_range)
  
  # Choose the function dynamically
  summarise_fn <- switch(summary_func,
                         mean = rowMeans,
                         sum = function(x, na.rm = TRUE) rowSums(x, na.rm = na.rm))
  
  data %>%
    mutate(!!sym(var_name) := as.numeric(!!sym(var_name))) %>%
    filter(!is.na(!!sym(var_name))) %>%
    
    group_by(study, days) %>%
    summarise(!!sym(var_name) := mean(!!sym(var_name), na.rm = TRUE), .groups = "drop") %>%
    
    pivot_wider(names_from = days, values_from = !!sym(var_name)) %>%
    
    mutate(!!sym(new_col_name) := summarise_fn(
      dplyr::select(., any_of(day_cols)), na.rm = TRUE
    )) %>%
    
    dplyr::select(study, !!sym(new_col_name)) |> 
    mutate(study = as.factor(study))
}


process_weather_var <- function(data, var_name, days_range, new_col_name,
                                summary_func = c("mean", "sum", "count_above"),
                                threshold = NULL) {
  summary_func <- match.arg(summary_func)
  day_cols <- as.character(days_range)

  # Dynamic function based on summary_func
  summarise_fn <- switch(summary_func,
    mean = function(x) rowMeans(x, na.rm = TRUE),
    sum = function(x) rowSums(x, na.rm = TRUE),
    count_above = {
      if (is.null(threshold)) stop("You must specify a threshold for count_above")
      function(x) rowSums(x > threshold, na.rm = TRUE)
    }
  )

  data %>%
    mutate(!!sym(var_name) := as.numeric(!!sym(var_name))) %>%
    filter(!is.na(!!sym(var_name))) %>%
    
    group_by(study, days) %>%
    summarise(!!sym(var_name) := mean(!!sym(var_name), na.rm = TRUE), .groups = "drop") %>%
    
    pivot_wider(names_from = days, values_from = !!sym(var_name)) %>%
    
    mutate(!!sym(new_col_name) := summarise_fn(
      dplyr::select(., any_of(day_cols))
    )) %>%
    
    dplyr::select(study, !!sym(new_col_name)) %>%
    mutate(study = as.factor(study))
}




# Process each variable with explicit package references
T2M_MIN_pred <- process_weather_var(data, "T2M_MIN", 2:10, "tmin")

T2MDEW_pred <- process_weather_var(data_nasa, "T2MDEW", 4:10, "dew")

RH2M_pred <- process_weather_var(data, "RH2M", 5:10, "rh")
PRECTOTCORR_pred <- process_weather_var(data_nasa, "PRECTOTCORR", 0:10, "prec", summary_func = "count_above", threshold = 5)
PRECTOTCORR_pred2 <- process_weather_var(data_nasa, "PRECTOTCORR", 6:10, "prec2", summary_func = "sum")
RH2M_pred2 <- process_weather_var(data_nasa, "RH2M", 5:10, "rh2", summary_func = "count_above", threshold = 85)


# Get epidemic status
epidemic <- data %>%
  dplyr::distinct(study, epidemic) %>%
  mutate(study = factor(study))

# Combine all data
df_predictors <- epidemic %>%
  dplyr::left_join(T2M_MIN_pred, by = "study") |> 
  dplyr::left_join(RH2M_pred, by = "study") |>  
  dplyr::left_join(RH2M_pred2, by = "study") |>  
  dplyr::left_join(PRECTOTCORR_pred, by = "study") |> 
  dplyr::left_join(PRECTOTCORR_pred2, by = "study") |> 
    dplyr::left_join(T2MDEW_pred, by = "study") 
  

```

## Logisticos e ensemble

```{r}

# Set up datadist for rms
dd <- datadist(df_predictors)
options(datadist = "dd")

# Convert epidemic to numeric
obs <- as.numeric(as.character(df_predictors$epidemic))

#-------------------------------------
# Fit base models and get probabilities
#-------------------------------------
models <- list(
  model1 = lrm(factor(epidemic) ~ tmin + rcs(rh, 4), data = df_predictors, x = TRUE, y = TRUE),
  model2 = lrm(factor(epidemic) ~ rcs(rh, 4) + rcs(dew, 3), data = df_predictors, x = TRUE, y = TRUE),
  model3 = lrm(factor(epidemic) ~ tmin + prec2, data = df_predictors, x = TRUE, y = TRUE)
)

# Predicted probabilities
p1 <- predict(models$model1, type = "fitted")
p2 <- predict(models$model2, type = "fitted")
p3 <- predict(models$model3, type = "fitted")

# Ensembles
ensemble_unw   <- (p1 + p2 + p3) / 3
ensemble_wgt   <- 0.102 * p1 + 0.43 * p2 + 0.46 * p3
stack_data     <- data.frame(p1 = p1, p2 = p2, p3 = p3, epidemic = factor(df_predictors$epidemic))
meta_model     <- glm(epidemic ~ p1 + p2 + p3, data = stack_data, family = binomial)
ensemble_stack <- predict(meta_model, type = "response")
print(meta_model)

#-----------------------------------------------------
# Function to compute evaluation metrics for a model
#-----------------------------------------------------
evaluate_model <- function(probs, threshold = 0.5, name = "model", type = "base") {
  pred <- ifelse(probs >= threshold, 1, 0)
  cm <- confusionMatrix(factor(pred), factor(obs), positive = "1")
  data.frame(
    Model = name,
    Type = type,
    Accuracy = cm$overall["Accuracy"],
    Sensitivity = cm$byClass["Sensitivity"],
    Specificity = cm$byClass["Specificity"]
  )
}

#-------------------------------------------------
# Evaluate all models and bind into a single table
#-------------------------------------------------
eval_df <- rbind(
  evaluate_model(p1, 0.53, "LM1", "Base"),
  evaluate_model(p2, 0.51, "LM2", "Base"),
  evaluate_model(p3, 0.46, "LM3", "Base"),
  evaluate_model(ensemble_unw, 0.475, "UNW", "Ensemble"),
  evaluate_model(ensemble_wgt, 0.45, "WGT", "Ensemble"),
  evaluate_model(ensemble_stack, 0.47, "STACK", "Ensemble"),
  evaluate_model(ensemble_majority, 0.5, "Majority vote", "Ensemble")
)

# Add Youden index to eval_df and sort
eval_df$Youden <- with(eval_df, Sensitivity + Specificity - 1)
eval_df <- eval_df[order(-eval_df$Youden), ]  # sort descending

# Factor Model by sorted order for consistent legend
eval_df$Model <- factor(eval_df$Model, levels = eval_df$Model)

# Sort by Youden
eval_df_sorted <- eval_df[order(-eval_df$Youden), ]
eval_df_sorted$Model <- factor(eval_df_sorted$Model, levels = eval_df_sorted$Model)

# View table
print(eval_df)

ggplot(eval_df, aes(x = Specificity, y = Sensitivity, size = Youden)) +
  geom_point(aes(color = Model, shape = Type), alpha = 0.9) +
  geom_text(aes(label = round(Youden, 2)), vjust = -1.2, size = 3.5) +
  scale_shape_manual(values = c(Base = 16, Ensemble = 17)) +
  scale_size(range = c(3, 7)) +
  labs(title = "Model Performance: Sensitivity vs Specificity",
       x = "Specificity", y = "Sensitivity") +
  theme_minimal() +
 theme(
    plot.title = element_text(size = 16, hjust = 0.5),  # título centralizado e maior
    axis.title.x = element_text(size = 14),             # título do eixo x maior
    axis.title.y = element_text(size = 14)              # título do eixo y maior
  )

# Bar plot
ggplot(eval_df_sorted, aes(x = Model, y = Youden, fill = Type)) +
  geom_col(alpha = 0.8, width = 0.7) +
  geom_text(aes(label = round(Youden, 2)), vjust = -0.5, size = 3.5) +
  scale_fill_manual(values = c("Base" = "steelblue", "Ensemble" = "darkorange")) +
  labs(title = "Model Comparison by Youden Index",
       x = "Model", y = "Youden Index") +
  theme_minimal() +
  theme(legend.position = "top")


# Plot
ggplot(eval_df, aes(x = Accuracy, y = Youden, color = Model, shape = Type)) +
  geom_point(size = 4, alpha = 0.9) +
  geom_text(aes(label = Model), vjust = -1.1, hjust = 0.5, size = 3.5, show.legend = FALSE, check_overlap = TRUE) +
  scale_shape_manual(values = c(Base = 16, Ensemble = 17)) +
  labs(
     x = "Accuracy", y = "Youden index"
  ) +
  theme_minimal() +
   theme(
    plot.title = element_text(size = 16, hjust = 0.5),  # título centralizado e maior
    axis.title.x = element_text(size = 14),             # título do eixo x maior
    axis.title.y = element_text(size = 14)              # título do eixo y maior
  )

  #theme(legend.position = "top")

predicted_prob <- ensemble_stack
predicted_prob <- predict(m_logistic, type = "fitted")

pr <- pr.curve(scores.class0 = predicted_prob[epidemic$epidemic == 1],
               scores.class1 = predicted_prob[epidemic$epidemic == 0],
               curve = TRUE)

pr_df <- data.frame(
  recall = pr$curve[,1],
  precision = pr$curve[,2],
  threshold = pr$curve[,3]
)

ggplot(pr_df, aes(x = recall, y = precision)) +
  geom_line(color = "#0072B2", size = 1.2) +
  labs(x = "Recall (Sensitivity)", y = "Precision (PPV)",
       title = "Precision-Recall Curve") +
  theme_bw() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

pr$auc.integral  # area under PR curve

roc_obj <- roc(response = epidemic$epidemic, predictor = predicted_prob)
roc_auc <- pROC::auc(roc_obj)
roc_auc


eval_df <- eval_df %>%
  mutate(
  ROC_AUC = case_when(
    Model == "LM1"  ~ 0.798,
    Model == "LM2"  ~ 0.792,
    Model == "LM3"  ~ 0.814,
    Model == "UNW"  ~ 0.833,
    Model == "WGT"  ~ 0.834,
    Model == "STACK"~ 0.826
  ),
  PR_AUC = case_when(
    Model == "LM1"  ~ 0.742,
    Model == "LM2"  ~ 0.754,
    Model == "LM3"  ~ 0.720,
    Model == "UNW"  ~ 0.785,
    Model == "WGT"  ~ 0.782,
    Model == "STACK"~ 0.784
  ))

a <- ggplot(eval_df, aes(x = Accuracy, y = Youden, color = Model, shape = Type)) +
  geom_point(alpha = 0.9, size = 4) +
  scale_shape_manual(values = c(Base = 16, Ensemble = 17)) +
  ggthemes::scale_color_excel_new() +
  labs(x = "Accuracy", y = "Youden index", size = "AUC") +
  theme_bw() +
  xlim(0.75, 0.85) +
  ylim(0.5, 0.7) +
  theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "bottom") + # coloca a legenda dentro do gráfico (coordenadas normalizadas) )
        guides(color = guide_legend(nrow = 1),  shape = "none") +# oculta legenda do Type
  scale_size_continuous(
  limits = c(0.79, 0.835),
  range = c(2, 8),         # controla o tamanho mínimo e máximo dos pontos
  breaks = c(0.80, 0.81, 0.82, 0.83), # define quais valores vão aparecer na legenda
  labels = scales::number_format(accuracy = 0.01) # formata os números na legenda
)


b <- ggplot(eval_df, aes(x = Sensitivity , y = Specificity, color = Model, shape = Type)) +
  geom_point(alpha = 0.9, size = 4) +
  ggthemes::scale_color_excel_new() +
  labs(x = "Sensitivity", y = "Specificity", size = "AUC") +
  theme_bw() +
  xlim(0.6, 0.8) +
  ylim(0.825, 0.90) +
  theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "bottom") + # coloca a legenda dentro do gráfico (coordenadas normalizadas) )
        guides(color = guide_legend(nrow = 1), shape = "none") +# oculta legenda do Type
  scale_size_continuous(
  limits = c(0.79, 0.835),
  range = c(2, 8),         # controla o tamanho mínimo e máximo dos pontos
  breaks = c(0.80, 0.81, 0.82, 0.83), # define quais valores vão aparecer na legenda
  labels = scales::number_format(accuracy = 0.01) # formata os números na legenda
)

c <- ggplot(eval_df, aes(x = ROC_AUC, y = PR_AUC, color = Model, shape = Type)) +
  geom_point(alpha = 0.9, size = 4) +
  scale_shape_manual(values = c(Base = 16, Ensemble = 17)) +
  ggthemes::scale_color_excel_new() +
  labs(x = "ROC_AUC", y = "PR_AUC") +
  theme_bw() +
  xlim(0.775, 0.85) +
  ylim(0.715, 0.80) +
  theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "bottom") + # coloca a legenda dentro do gráfico (coordenadas normalizadas) )
        guides(color = guide_legend(nrow = 1),  shape = "none") +# oculta legenda do Type
  scale_size_continuous(
  limits = c(0.79, 0.835),
  range = c(2, 8),         # controla o tamanho mínimo e máximo dos pontos
  breaks = c(0.80, 0.81, 0.82, 0.83), # define quais valores vão aparecer na legenda
  labels = scales::number_format(accuracy = 0.01) # formata os números na legenda
)

c
b <- ggplot(eval_df, aes(x = Sensitivity , y = Specificity, color = Model, shape = Type)) +
  geom_point(alpha = 0.9, size = 8) +
  ggthemes::scale_color_excel_new() +
  labs(x = "Sensitivity", y = "Specificity", size = "AUC") +
  theme_bw() +
  xlim(0.6, 0.8) +
  ylim(0.825, 0.90) +
  theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "bottom") + # coloca a legenda dentro do gráfico (coordenadas normalizadas) )
        guides(color = guide_legend(nrow = 1), shape = "none") +# oculta legenda do Type
  scale_size_continuous(
  limits = c(0.79, 0.835),
  range = c(2, 8),         # controla o tamanho mínimo e máximo dos pontos
  breaks = c(0.80, 0.81, 0.82, 0.83), # define quais valores vão aparecer na legenda
  labels = scales::number_format(accuracy = 0.01) # formata os números na legenda
)


(a/b/c) +
  plot_layout(guides = "collect") &
  plot_annotation(tag_levels = "A")& 
  theme(legend.position = "bottom")
  
ggsave("imagem_3_3.png", dpi = 600, bg = "white", width = 4, height = 9.5)


```

```{r}
# Número de observações
n <- nrow(stack_data)

# Log-likelihoods
ll_null <- logLik(glm(epidemic ~ 1, data = stack_data, family = binomial))
ll_full <- logLik(meta_model)

# Cox-Snell R²
cs_r2 <- 1 - exp((2 / n) * (ll_null - ll_full))

# Nagelkerke R²
max_r2 <- 1 - exp((2 / n) * as.numeric(ll_null))
nag_r2 <- cs_r2 / max_r2

cat("Cox-Snell R²:", cs_r2, "\n")
cat("Nagelkerke R²:", nag_r2, "\n")


dd <- datadist(stack_data)
options(datadist = "dd")
fit_stacked <- lrm(epidemic ~ p1 + p2 + p3, data = stack_data, x = TRUE, y = TRUE)
val <- validate(fit_stacked, B = 100)
Dxy <- val["Dxy", "index.corrected"]
B <- val["B", "index.corrected"]
auc <- (Dxy + 1) / 2
B

library(pROC)

# Para o modelo unweighted
roc_unweighted <- roc(df_predictors$epidemic, ensemble_unw)

# Para o modelo weighted
roc_weighted <- roc(df_predictors$epidemic, ensemble_wgt)


# Transformar resposta em 0 e 1, se ainda não estiver
obs <- as.numeric(df_predictors$epidemic) 

# Calcular o Brier Score
brier_unweighted <- mean((ensemble_unw - obs)^2)
brier_weighted <- mean((ensemble_wgt - obs)^2)


```

```{r}
# Cut-points para classificação binária
cut_p1 <- 0.530
cut_p2 <- 0.51
cut_p3 <- 0.460

# Classificações binárias
class_p1 <- ifelse(p1 >= cut_p1, 1, 0)
class_p2 <- ifelse(p2 >= cut_p2, 1, 0)
class_p3 <- ifelse(p3 >= cut_p3, 1, 0)

# Função votação majoritária
majority_vote <- function(...) {
  votes <- c(...)
  if (sum(votes) >= ceiling(length(votes)/2)) {
    return(1)
  } else {
    return(0)
  }
}

# Aplica a votação majoritária para cada observação
ensemble_majority <- mapply(majority_vote, class_p1, class_p2, class_p3)

# Se quiser avaliar, supondo que você tenha o vetor real 'actual'
# accuracy:
accuracy <- mean(ensemble_majority == actual)
cat("Ensemble majority vote accuracy:", accuracy, "\n")

# Também pode montar um data.frame com os resultados e avaliar outros índices
results_df <- data.frame(actual = actual,
                         p1 = p1, class_p1 = class_p1,
                         p2 = p2, class_p2 = class_p2,
                         p3 = p3, class_p3 = class_p3,
                         ensemble_majority = ensemble_majority)

# Ensemble unweighted: média das predições contínuas

cutoff_unweighted <- 0.52
ensemble_unweighted_class <- ifelse(ensemble_unw >= cutoff_unweighted, 1, 0)

# Criando o dataframe de comparação
results_compare <- data.frame(
  ensemble_majority = ensemble_majority,
  ensemble_unweighted = ensemble_unweighted_class,
  actual = actual
)

# Visualizar algumas linhas para comparar
head(results_compare)

# Opcional: calcular concordância entre os dois ensembles
agreement <- mean(results_compare$ensemble_majority == results_compare$ensemble_unweighted)
cat("Agreement between majority vote and unweighted ensemble:", agreement, "\n")
```

```{r}
# Predicted probabilities
predicted_prob <- ensemble_majority
actual <- df_predictors$epidemic
brier_score <- mean((predicted_prob - actual)^2)
cat("Brier Score:", brier_score, "\n")

preds <- data.frame(1, actual, predicted_prob)
o <- optimal.thresholds(preds)
o_unw <- o$predicted_prob[3]
o_unw

# Classification and accuracy
predicted <- ifelse(predicted_prob > o_unw, 1, 0)
accuracy <- mean(predicted == actual)
cat("Accuracy:", accuracy, "\n")

# Confusion matrix at 0.55 threshold
cmax <- confusionMatrix(data = as.factor(predicted),
                reference = as.factor(actual),
                mode = "everything",
                positive = "1")

Sensitivity <- cmax$byClass["Sensitivity"]
Specificity = cmax$byClass["Specificity"]

# Youden index
Youden <- (Sensitivity + Specificity - 1)
cat("Youden Index:", Youden, "\n")

```

```{r}
# Parâmetros
set.seed(123)
B <- 1000
data_orig <- df_predictors   # substitua pelo seu data frame original
y_orig <- data_orig$epidemic          # substitua pelo nome da sua variável resposta (0/1)

# Bootstrap loop para estimar otimismo
optim_unw <- numeric(B)
optim_wgt <- numeric(B)

# Função para calcular o Brier score
brier <- function(p, y) mean((p - y)^2)

for (b in 1:B) {
  # Amostra bootstrap
  idx_boot <- sample(seq_len(nrow(data_orig)), replace = TRUE)
  bootdata <- data_orig[idx_boot, ]

  # Reajuste dos modelos no bootstrap
  fit1_b <- update(models$model1, data = bootdata)
  fit2_b <- update(models$model2, data = bootdata)
  fit3_b <- update(models$model3, data = bootdata)

  # --- Desempenho aparente no bootstrap ---
  p1_boot_onboot <- predict(fit1_b, newdata = bootdata, type = "fitted")
  p2_boot_onboot <- predict(fit2_b, newdata = bootdata, type = "fitted")
  p3_boot_onboot <- predict(fit3_b, newdata = bootdata, type = "fitted")
  
  ens_unw_boot_onboot <- (p1_boot_onboot + p2_boot_onboot + p3_boot_onboot) / 3
  ens_wgt_boot_onboot <- 0.102 * p1_boot_onboot + 0.43 * p2_boot_onboot + 0.46 * p3_boot_onboot

  brier_unw_boot_onboot <- brier(ens_unw_boot_onboot, bootdata$epidemic)
  brier_wgt_boot_onboot <- brier(ens_wgt_boot_onboot, bootdata$epidemic)

  # --- Desempenho no dataset original (teste) ---
  p1_boot_onorig <- predict(fit1_b, newdata = data_orig, type = "fitted")
  p2_boot_onorig <- predict(fit2_b, newdata = data_orig, type = "fitted")
  p3_boot_onorig <- predict(fit3_b, newdata = data_orig, type = "fitted")

  ens_unw_boot_onorig <- (p1_boot_onorig + p2_boot_onorig + p3_boot_onorig) / 3
  ens_wgt_boot_onorig <- 0.102 * p1_boot_onorig + 0.43 * p2_boot_onorig + 0.46 * p3_boot_onorig

  brier_unw_boot_onorig <- brier(ens_unw_boot_onorig, y_orig)
  brier_wgt_boot_onorig <- brier(ens_wgt_boot_onorig, y_orig)

  # Otimismo = desempenho bootstrap - desempenho teste
  optim_unw[b] <- brier_unw_boot_onboot - brier_unw_boot_onorig
  optim_wgt[b] <- brier_wgt_boot_onboot - brier_wgt_boot_onorig
}

# -----------------------------
# 4. Brier score corrigido
# -----------------------------
brier_unw_corrected <- brier_unweighted + mean(optim_unw)  # adiciona otimismo (Brier é erro)
brier_wgt_corrected <- brier_weighted + mean(optim_wgt)

cat("Brier corrigido (ensemble_unw):", round(brier_unw_corrected, 4), "\n")
cat("Brier corrigido (ensemble_wgt):", round(brier_wgt_corrected, 4), "\n")
```

## logistic metrics model 1

```{r}

# Fit logistic model with restricted cubic splines
#m_logistic <- lrm(factor(epidemic) ~ rcs(tmin, 3) + rcs(rh, 4), 
#                  data = df_predictors, x = TRUE, y = TRUE)
m_logistic <- lrm(factor(epidemic) ~ tmin + rcs(rh, 4), 
                  data = df_predictors, x = TRUE, y = TRUE)

AIC(m_logistic)
AIC(m_logistic_teste)

anova(m_logistic)

# Summary and model fit statistics
print(m_logistic)
nagelkerke_r2 <- m_logistic$stats["R2"]
cox_snell_r2 <- nagelkerke_r2 * (1 - exp(-m_logistic$stats["Model L.R."] / nrow(df_predictors)))
cat("Nagelkerke R²:", nagelkerke_r2, "\n")
cat("Cox-Snell R²:", cox_snell_r2, "\n")

# Predicted probabilities
predicted_prob <- predict(m_logistic, type = "fitted")
actual <- df_predictors$epidemic
brier_score <- mean((predicted_prob - actual)^2)
cat("Brier Score:", brier_score, "\n")

# ROC and AUC
roc_curve <- roc(actual, predicted_prob)
auc.roc.plot(data.frame(1, actual, predicted_prob))

#################################### ensembles YI 
#preds <- data.frame(1, actual, ensemble_unw)
#o <- optimal.thresholds(preds)
#o_unw <- o$ensemble_unw[3]
#o_unw

preds <- data.frame(1, actual, ensemble_wgt)
o <- optimal.thresholds(preds)
o_wgt <- o$ensemble_wgt[3]
o_wgt

#preds <- data.frame(1, actual, ensemble_stack)
#o <- optimal.thresholds(preds)
#o_sta <- o$ensemble_stack[3]
#o_sta

######################################################################
# Optimal threshold analysis
preds <- data.frame(1, actual, predicted_prob)
o <- optimal.thresholds(preds)
o1 <- o$predicted_prob[3]


# Classification and accuracy
predicted <- ifelse(predicted_prob > o1, 1, 0)
accuracy <- mean(predicted == actual)
cat("Accuracy:", accuracy, "\n")

# Confusion matrix at 0.55 threshold
confusionMatrix(data = as.factor(predicted),
                reference = as.factor(actual),
                mode = "everything")


# Calibration: bootstrap and cross-validation
cal_boot <- calibrate(m_logistic, method = "boot", B = 1000)
plot(cal_boot, main = "Calibration Plot (Bootstrap)", col = "red")

cal_cv <- calibrate(m_logistic, method = "crossvalidation", B = 10)
plot(cal_cv, main = "Calibration Plot (Cross-validation)")

# rms-style calibration plot
val.prob(predicted_prob, actual, pl = TRUE, smooth = TRUE)

# Internal validation
validation_boot <- validate(m_logistic, method = "boot", B = 1000)
print(validation_boot)


validation_cv <- validate(m_logistic, method = "crossvalidation", B = 10)
print(validation_cv)

# Predictive plot
pred <- plot(Predict(m_logistic, fun = plogis), conf.int = TRUE,
     ylab = "Predicted Probability")

pred 

```

```{r}
# Supondo que você já tem o modelo m_logistic
pred_obj <- Predict(m_logistic, fun = plogis, conf.int = 0.95)

# Converte em data.frame
pred_df <- as.data.frame(pred_obj)
pred_df_tmin <- pred_df |> 
  filter(.predictor. == "tmin")

# Plota com ggplot2
tmin_spline <- ggplot(pred_df_tmin, aes(x = tmin, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "Tmin<sub>2_10</sub> (°C)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))

pred_df_rh <- pred_df |> 
  filter(.predictor. == "rh")

# Plota com ggplot2
rh_spline <- ggplot(pred_df_rh, aes(x = rh, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "RH<sub>5_10</sub> (%)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))

# Supondo que você já tem o modelo m_logistic
pred_obj2 <- Predict(m_logistic2, fun = plogis, conf.int = 0.95)

# Converte em data.frame
pred_df2 <- as.data.frame(pred_obj2)
pred_df_dew <- pred_df2 |> 
  filter(.predictor. == "dew")

# Plota com ggplot2
tdew_spline <- ggplot(pred_df_dew, aes(x = dew, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "Tdew<sub>4_10</sub> (°C)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))


pred_df2 <- as.data.frame(pred_obj2)
pred_df2_rh <- pred_df2 |> 
  filter(.predictor. == "rh")

# Plota com ggplot2
trh2_spline <- ggplot(pred_df2_rh, aes(x = rh, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "RH<sub>5_10</sub> (%)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))

# Supondo que você já tem o modelo m_logistic
pred_obj3 <- Predict(m_logistic3, fun = plogis, conf.int = 0.95)

# Converte em data.frame
pred_df3 <- as.data.frame(pred_obj3)
pred_df_rain <- pred_df3 |> 
  filter(.predictor. == "prec2")

# Plota com ggplot2
prec_spline <- ggplot(pred_df_rain, aes(x = prec2, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "PREC<sub>6_10</sub> (mm)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))+
  scale_x_continuous(breaks = pretty_breaks(n = 5))

# Converte em data.frame
pred_df3 <- as.data.frame(pred_obj3)
pred_df3_tmin <- pred_df3 |> 
  filter(.predictor. == "tmin")

# Plota com ggplot2
tmin3_spline <- ggplot(pred_df3_tmin, aes(x = tmin, y = yhat)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, fill = "#4970b5") +
  geom_line(color = "#ed7d31", size = 1.5) +
  labs(x = "Tmin<sub>2_10</sub> (°C)", y = "Predicted Probability") +
  theme_bw()+
  theme(
    axis.title.x = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.y = element_text(size = 12),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )+
  scale_y_continuous(limits = c(0.00, 1.00), breaks = breaks_width(0.25))+
  scale_x_continuous(breaks = pretty_breaks(n = 5))


library(patchwork)

(tmin_spline | rh_spline) /
(trh2_spline | tdew_spline) /
(tmin3_spline | prec_spline) +
  plot_layout(guides = "collect") &  # coleta todas as legendas em uma só
  theme(legend.position = "bottom") &  # define a posição da legenda
    plot_annotation(tag_levels = "A")

  
#ggsave("imagem_4.png", dpi = 300, bg = "white", width = 10, height = 11)



```

```{r}
# Packages
library(pROC)
library(PRROC)
library(rms)

# Função para PR-AUC (retorna NA se faltar alguma classe)
pr_auc_fun <- function(y, p) {
  y <- as.integer(y)
  if (length(unique(y)) < 2) return(NA_real_)
  PRROC::pr.curve(
    scores.class0 = p[y == 1],
    scores.class1 = p[y == 0],
    curve = FALSE
  )$auc.integral
}

# ---- Dados e modelo já existentes ----
# m_logistic: objeto lrm
# df_predictors: data.frame usado no ajuste
# Abaixo identifico automaticamente a coluna-resposta:
resp_var <- all.vars(formula(m_logistic))[1]
y_full   <- df_predictors[[resp_var]]
p_full   <- predict(m_logistic, type = "fitted")

# PR-AUC "aparente" do modelo ajustado em todos os dados
pr_auc_apparent <- pr_auc_fun(y_full, p_full)

# ---- Bootstrap para estimar otimismo (mesma lógica do validate.rms) ----
set.seed(123)
B <- 1000
n <- nrow(df_predictors)
opt_vec <- numeric(B)

for (b in 1:B) {
  idx_boot <- sample.int(n, replace = TRUE)
  dat_boot <- df_predictors[idx_boot, , drop = FALSE]

  # refita o modelo na amostra bootstrap
  fit_b <- update(m_logistic, data = dat_boot)

  # PR-AUC aparente (no próprio bootstrap)
  y_boot <- dat_boot[[resp_var]]
  p_boot <- predict(fit_b, type = "fitted")
  pr_apparent_b <- pr_auc_fun(y_boot, p_boot)

  # PR-AUC testado no conjunto original com o mesmo modelo bootstrapped
  p_test_on_orig <- predict(fit_b, newdata = df_predictors, type = "fitted")
  pr_test_b <- pr_auc_fun(y_full, p_test_on_orig)

  # Otimismo desta réplica
  opt_vec[b] <- pr_apparent_b - pr_test_b
}

opt_mean <- mean(na.omit(opt_vec))
pr_auc_corrected <- pr_auc_apparent - opt_mean

cat("PR-AUC aparente   :", round(pr_auc_apparent, 3), "\n")
cat("Otimismo (médio)  :", round(opt_mean, 3), "\n")
cat("PR-AUC corrigido  :", round(pr_auc_corrected, 3), "\n")

# Intervalo de confiança (percentil) para a métrica "testada no original"
# (opcional, útil como IC do desempenho esperado)
pr_auc_test_vec <- numeric(B)
set.seed(123)
for (b in 1:B) {
  idx_boot <- sample.int(n, replace = TRUE)
  dat_boot <- df_predictors[idx_boot, , drop = FALSE]
  fit_b <- update(m_logistic, data = dat_boot)
  p_test_on_orig <- predict(fit_b, newdata = df_predictors, type = "fitted")
  pr_auc_test_vec[b] <- pr_auc_fun(y_full, p_test_on_orig)
}
ci <- quantile(na.omit(pr_auc_test_vec), c(0.025, 0.975))
cat("IC95% (percentil) :", round(ci, 3), "\n")



```

```{r}
set.seed(123)
B <- 1000
n <- length(y_full)   # número de observações
opt_vec_unw <- numeric(B)

for (b in 1:B) {
  idx_boot <- sample.int(n, replace = TRUE)
  y_boot <- y_full[idx_boot]
  p_boot <- ensemble_stack[idx_boot]  # substitua por ensemble_wgt ou ensemble_stack

  # PR-AUC aparente no bootstrap
  pr_apparent_b <- pr_auc_fun(y_boot, p_boot)

  # PR-AUC testado no conjunto original
  pr_test_b <- pr_auc_fun(y_full, ensemble_stack)  # mesmo conjunto original

  # Otimismo
  opt_vec_unw[b] <- pr_apparent_b - pr_test_b
}

opt_mean <- mean(na.omit(opt_vec_unw))
pr_auc_apparent <- pr_auc_fun(y_full, ensemble_stack)
pr_auc_corrected <- pr_auc_apparent - opt_mean

cat("PR-AUC aparente   :", round(pr_auc_apparent, 3), "\n")
cat("Otimismo (médio)  :", round(opt_mean, 3), "\n")
cat("PR-AUC corrigido  :", round(pr_auc_corrected, 3), "\n")

```

## logistic metrics model 2

```{r}
# Fit logistic model with restricted cubic splines
m_logistic2 <- lrm(factor(epidemic) ~ rcs(rh, 4) + rcs(dew, 3), 
                  data = df_predictors, x = TRUE, y = TRUE)

# Summary and model fit statistics
print(m_logistic2)
nagelkerke_r2 <- m_logistic2$stats["R2"]
cox_snell_r2 <- nagelkerke_r2 * (1 - exp(-m_logistic2$stats["Model L.R."] / nrow(df_predictors)))
cat("Nagelkerke R²:", nagelkerke_r2, "\n")
cat("Cox-Snell R²:", cox_snell_r2, "\n")

# Predicted probabilities
predicted_prob <- predict(m_logistic2, type = "fitted")
actual <- df_predictors$epidemic
brier_score <- mean((predicted_prob - actual)^2)
cat("Brier Score:", brier_score, "\n")

# ROC and AUC
roc_curve <- roc(actual, predicted_prob)
roc_ml2 <- auc.roc.plot(data.frame(1, actual, predicted_prob))



# Optimal threshold analysis
preds <- data.frame(1, actual, predicted_prob)
o <- optimal.thresholds(preds)
o2 <- o$predicted_prob[3]
o2

# Classification and accuracy
predicted <- ifelse(predicted_prob > o2, 1, 0)
accuracy <- mean(predicted == actual)
cat("Accuracy:", accuracy, "\n")

# Confusion matrix at 0.55 threshold
confusionMatrix(data = as.factor(predicted),
                reference = as.factor(actual),
                mode = "everything")


# Calibration: bootstrap and cross-validation
cal_boot <- calibrate(m_logistic2, method = "boot", B = 1000)
plot(cal_boot, main = "Calibration Plot (Bootstrap)", col = "red")

cal_cv <- calibrate(m_logistic2, method = "crossvalidation", B = 10)
plot(cal_cv, main = "Calibration Plot (Cross-validation)")

# rms-style calibration plot
val.prob(predicted_prob, actual, pl = TRUE, smooth = TRUE)

# Internal validation
validation_boot <- validate(m_logistic2, method = "boot", B = 1000)
print(validation_boot)

validation_cv <- validate(m_logistic2, method = "crossvalidation", B = 10)
print(validation_cv)

# Predictive plot
ggplot(Predict(m_logistic2), conf.int = TRUE)

pred2 <- plot(Predict(m_logistic2, fun = plogis), conf.int = TRUE,
     ylab = "Predicted Probability")

pred2

```

## logistic metrics model 3

```{r}
# Fit logistic model with restricted cubic splines
#m_logistic3 <- lrm(factor(epidemic) ~ rcs(tmin, 3) + prec2, 
#                  data = df_predictors, x = TRUE, y = TRUE)
m_logistic3 <- lrm(factor(epidemic) ~ tmin + prec2, 
                  data = df_predictors, x = TRUE, y = TRUE)

AIC(m_logistic3)
AIC(m_logistic3_teste)
anova(m_logistic3)
# Summary and model fit statistics
print(m_logistic3)
nagelkerke_r2 <- m_logistic3$stats["R2"]
cox_snell_r2 <- nagelkerke_r2 * (1 - exp(-m_logistic3$stats["Model L.R."] / nrow(df_predictors)))
cat("Nagelkerke R²:", nagelkerke_r2, "\n")
cat("Cox-Snell R²:", cox_snell_r2, "\n")

# Predicted probabilities
predicted_prob <- predict(m_logistic3, type = "fitted")
actual <- df_predictors$epidemic
brier_score <- mean((predicted_prob - actual)^2)
cat("Brier Score:", brier_score, "\n")

# ROC and AUC
roc_curve <- roc(actual, predicted_prob)
roc_ml3 <- auc.roc.plot(data.frame(1, actual, predicted_prob))



# Optimal threshold analysis
preds <- data.frame(1, actual, predicted_prob)
o <- optimal.thresholds(preds)
o3 <- o$predicted_prob[3]
o3

# Classification and accuracy
predicted <- ifelse(predicted_prob > o3, 1, 0)
accuracy <- mean(predicted == actual)
cat("Accuracy:", accuracy, "\n")

# Confusion matrix at 0.55 threshold
confusionMatrix(data = as.factor(predicted),
                reference = as.factor(actual),
                mode = "everything")


# Calibration: bootstrap and cross-validation
cal_boot <- calibrate(m_logistic3, method = "boot", B = 1000)
plot(cal_boot, main = "Calibration Plot (Bootstrap)", col = "red")

cal_cv <- calibrate(m_logistic3, method = "crossvalidation", B = 10)
plot(cal_cv, main = "Calibration Plot (Cross-validation)")

# rms-style calibration plot
val.prob(predicted_prob, actual, pl = TRUE, smooth = TRUE)

# Internal validation
validation_boot <- validate(m_logistic3, method = "boot", B = 1000)
print(validation_boot)

validation_cv <- validate(m_logistic3, method = "crossvalidation", B = 10)
print(validation_cv)

# Predictive plot
ggplot(Predict(m_logistic3), conf.int = TRUE)

pred3 <- plot(Predict(m_logistic3, fun = plogis), conf.int = TRUE,
     ylab = "Predicted Probability")

pred3

```

## Cria janelas

```{r}
# Define the intervals
window_size <- 10
start_days <- -28:(27 - window_size + 1)

intervals <- lapply(start_days, function(s) c(s, s + window_size - 1))

# List of variables to summarize
vars <- c("T2M_MIN", "RH2M", "PRECTOTCORR")

# Function to compute a summary variable for a period
summarize_period <- function(data, var, period, label) {
  var_sym <- sym(var)
  start_day <- period[1]
  end_day <- period[2]
  period_name <- paste0(var, "_", label)

  data %>%
    dplyr::select(study, days, !!var_sym) %>%
    group_by(study, days) %>%
    summarise(value = mean(!!var_sym, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = days, values_from = value) %>%
    mutate(!!period_name := rowMeans(across(as.character(start_day:end_day)), na.rm = TRUE)) %>%
    dplyr::select(study, !!period_name) %>%
    mutate(study = factor(study))
}

# Create all variable summaries for all intervals
# Function to format day labels
format_day <- function(day) {
  if (day < 0) paste0("n", abs(day)) else as.character(day)
}

# Create all variable summaries for all intervals with clean labels
summaries <- cross2(vars, intervals) %>%
  imap(~ {
    var <- .x[[1]]
    period <- .x[[2]]
    label <- paste0(format_day(period[1]), "_", format_day(period[2]))
    summarize_period(
      data = data,
      var = var,
      period = period,
      label = label
    )
  })

# Create epidemic base
epidemic <- data %>%
  dplyr::select(study, epidemic) %>%
  group_by(study) %>%
  slice(1) %>%
  mutate(study = factor(study))

# Join all summaries and epidemic
final_df <- reduce(summaries, left_join, by = "study") %>%
  left_join(epidemic, by = "study")
final_df2 <- na.omit(final_df)

```

## Boxplots

```{r}
cultivar <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1MBiKsosQ8Hob6LkS65_1pPU25hx1CO9i42Sm_xf28ww/edit?usp=sharing") |> 
    filter(!study %in% 126:150)

theme_set(r4pde::theme_r4pde())
p_tmin1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), tmin))+
  geom_boxplot()+
  labs(y = "T <sub>min 2_10</sub> °C", x = "Epidemic") +
  theme(
    axis.title.y = element_markdown()  # enable Markdown in Y-axis label
  )

p_dew1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), dew))+
  geom_boxplot()+
  labs(y = "T<sub>dew 4_10</sub> °C", x = "Epidemic")+
  theme(
    axis.title.y = element_markdown()  # enable Markdown in Y-axis label
  )

p_rh1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), rh))+
  geom_boxplot()+
  labs(x = "Epidemic", y = "RH <sub>5_10</sub> (%)")+
  theme(
    axis.title.y = element_markdown()  # enable Markdown in Y-axis label
  )
p_prec1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), prec2))+
  geom_boxplot()+
  labs(x = "Epidemic", y = "PREC <sub>6_10</sub> (mm)")+
    theme(
    axis.title.y = element_markdown()  # enable Markdown in Y-axis label
  )


library(patchwork)

((p_tmin1 | p_dew1)/
  (p_rh1 | p_prec1)) + plot_annotation(tag_levels = "A")

```

## Plots FDA

```{r}


## T2M_MIN


trials_weather_summary <- data |>
  group_by(epidemic, days) |>
  summarise(mean_tmin = mean(T2M_MIN, na.rm = TRUE), .groups = 'drop')


p_temp <- ggplot(trials_weather_summary, aes(x = days, y = mean_tmin, color = factor(epidemic), group = epidemic)) +
  annotate("rect", xmin = 2, xmax = 10, ymin = -Inf, ymax = Inf, 
           alpha = 0.4, fill = "grey") + # Add a shaded rectangle
  geom_line(linewidth = 1, alpha = 0.9) +
 # geom_smooth(span = 0.5, linewidth = 2, se = FALSE)+
  labs(
    title = "",
    x = "Days relative to flowering",
    y = "T<sub>min 2_10</sub> (°C)",
    color = "Epidemic") +
    scale_color_viridis_d(option = "E", begin = 0, end = 0.9)+
   scale_x_continuous(n.breaks = 16)+
  scale_y_continuous(n.breaks = 9)+
  geom_vline(xintercept = 0, linetype = 2)+
  theme(
    axis.title.y = element_markdown() ,
    legend.position = "top"
  )





# Dew 4_10
trials_weather_summary <- data_nasa |>
  group_by(epidemic, days) |>
  summarise(mean_dew = mean(T2MDEW, na.rm = TRUE), .groups = 'drop')
p_dew <- ggplot(trials_weather_summary, aes(x = days, y = mean_dew, color = factor(epidemic), group = epidemic)) +
  annotate("rect", xmin = 4, xmax = 10, ymin = -Inf, ymax = Inf, 
           alpha = 0.4, fill = "grey") + # Add a shaded rectangle
  geom_line(linewidth = 1, alpha = 0.9) +
 # geom_smooth(span = 0.5, linewidth = 2, se = FALSE)+
  labs(
    title = "",
    x = "Days relative to flowering",
    y = "T<sub>dew 4_10</sub> (°C)",
    color = "Epidemic") +
    scale_color_viridis_d(option = "E", begin = 0, end = 0.9)+
  scale_x_continuous(n.breaks = 16)+
  scale_y_continuous(n.breaks = 9)+
  geom_vline(xintercept = 0, linetype = 2)+
  theme(
    axis.title.y = element_markdown()  ,
    legend.position = "top")


# RH 5_10
trials_weather_summary <- data |>
  group_by(epidemic, days) |>
  summarise(mean_rh = mean(RH2M, na.rm = TRUE), .groups = 'drop')
p_rh <- ggplot(trials_weather_summary, aes(x = days, y = mean_rh, color = factor(epidemic), group = epidemic)) +
  annotate("rect", xmin = 6, xmax = 10, ymin = -Inf, ymax = Inf, 
           alpha = 0.4, fill = "grey") + # Add a shaded rectangle
  geom_line(linewidth = 1, alpha = 0.9) +
 # geom_smooth(span = 0.5, linewidth = 2, se = FALSE)+
  labs(
    title = "",
    x = "Days relative to flowering",
    y = "RH <sub>5_10</sub> (°C)",
    color = "Epidemic") +
    scale_color_viridis_d(option = "E", begin = 0, end = 0.9)+
  scale_x_continuous(n.breaks = 16)+
  scale_y_continuous(n.breaks = 9)+
  geom_vline(xintercept = 0, linetype = 2)+
  theme(
    axis.title.y = element_markdown() ,
    legend.position = "top" 
  )



# PREC 6_10
trials_weather_summary <- data |>
  group_by(epidemic, days) |>
  summarise(mean_prec = mean(PRECTOTCORR, na.rm = TRUE), .groups = 'drop')
p_prec <- ggplot(trials_weather_summary, aes(x = days, y = mean_prec, color = factor(epidemic), group = epidemic)) +
  annotate("rect", xmin = 6, xmax = 10, ymin = -Inf, ymax = Inf, 
           alpha = 0.4, fill = "grey") + # Add a shaded rectangle
  geom_line(linewidth = 1, alpha = 0.9) +
 # geom_smooth(span = 0.5, linewidth = 2, se = FALSE)+
  labs(
    title = "",
    x = "Days relative to flowering",
    y = "Cumul. rainfall <sub>6_10</sub> (mm)",
    color = "Epidemic") +
    scale_color_viridis_d(option = "E", begin = 0, end = 0.9)+
  scale_x_continuous(n.breaks = 16)+
  scale_y_continuous(n.breaks = 9)+
  geom_vline(xintercept = 0, linetype = 2)+
  theme(
    axis.title.y = element_markdown() ,
    legend.position = "top" 
  )


((p_temp | p_dew) / (p_rh | p_prec))+ plot_annotation(tag_levels = "A")+
plot_layout(guides = "collect") &
  theme(legend.position = "bottom")


```

## Lasso

```{r}

library(glmnet)
weather_vars <- final_df2
set.seed(123)
lambdas <- 10^seq(2, -3, by = -.1)

weather_vars$epidemic <- as.factor(weather_vars$epidemic)

y <- weather_vars %>%
  dplyr::select(epidemic) %>%
  as.matrix()



X <- weather_vars%>%
  ungroup() |> 
  dplyr::select(-epidemic, - study) %>%
  as.matrix()


# Setting alpha = 1 implements lasso regression
lasso_reg_1week <- cv.glmnet(X, y,
  alpha = 0.5,
  family = "binomial",
  lambda = lambdas,
  standardize = TRUE,
  nfolds = 5
)
plot(lasso_reg_1week)

# Best
lambda_best_1week <- lasso_reg_1week$lambda.min
lambda_best_1week

lasso_model_1week <- glmnet(X,
  y,
  alpha = 1,
  family = "binomial",
  lambda = lambda_best_1week,
  standardize = TRUE
)
coef(lasso_model_1week)
assess.glmnet(lasso_model_1week,
  newx = X,
  newy = y
)

plot(roc.glmnet(lasso_model_1week,
  newx = X,
  newy = factor(y)
),
type = "l"
) 

```

## Best glm

```{r}
library(bestglm)

# Extract non-zero coefficient names (exclude intercept)
lasso_coefs <- coef(lasso_model_1week)
selected_vars <- rownames(lasso_coefs)[which(lasso_coefs > 0)]
selected_vars <- selected_vars[!selected_vars %in% c("(Intercept)")]
selected_vars
# Subset data
X_selected <- weather_vars %>% dplyr::select(all_of(selected_vars))

# Response as numeric 0/1
df_bestglm <- data.frame(
  Y = (weather_vars$epidemic),  # must be numeric 0/1
  weather_vars %>% dplyr::select(all_of(selected_vars))
)

#df_bestglm$Y <- as.numeric(df_bestglm$Y)

# Step 2: confirm response looks correct
table(df_bestglm$Y)  # Should show both 0s and 1s

# Step 3: ensure no NA values
df_bestglm <- na.omit(df_bestglm)

df_bestglm <- df_bestglm %>%
  dplyr::select(-Y, everything(), Y)


# Step 4: run bestglm (exhaustive, limit to nvmax = 10)
library(bestglm)
best_model <- bestglm(
  Xy = df_bestglm,
  family = binomial,     # NOT family = binomial()
  IC = "BIC",
  TopModels = 50000,
  method = "exhaustive",
  nvmax = 10
)




library(MASS)

glm_full <- glm(Y ~ ., data = df_bestglm, family = binomial)
step_model <- stepAIC(glm_full, direction = "both", trace = FALSE)

summary(step_model)



formula_full <- as.formula(paste("Y ~", paste(selected_vars, collapse = "+")))
m_logistic <- glm(formula_full, family = binomial, data = df_bestglm)


```

## K-folds cv logistico rms

```{r}
library(rms)
library(caret)
library(pROC)
library(dplyr)

set.seed(123)
folds <- createFolds(df_predictors$epidemic, k = 10, returnTrain = FALSE)

# Storage
oof_preds <- data.frame(id = 1:nrow(df_predictors),
                        obs = as.numeric(as.character(df_predictors$epidemic)),
                        p1 = NA, p2 = NA, p3 = NA)

for (i in seq_along(folds)) {
  idx <- folds[[i]]
  train <- df_predictors[-idx, ]
  test  <- df_predictors[idx, ]
  
  dd <- datadist(train); options(datadist = "dd")
  
  # Base models
  m1 <- lrm(factor(epidemic) ~ rcs(tmin, 3) + rcs(rh, 4), data = train, x = TRUE, y = TRUE)
  m2 <- lrm(factor(epidemic) ~ rcs(rh, 4) + rcs(dew, 3), data = train, x = TRUE, y = TRUE)
  m3 <- lrm(factor(epidemic) ~ rcs(tmin, 3) + prec2, data = train, x = TRUE, y = TRUE)
  
  # Predict on held-out fold
  oof_preds$p1[idx] <- predict(m1, newdata = test, type = "fitted")
  oof_preds$p2[idx] <- predict(m2, newdata = test, type = "fitted")
  oof_preds$p3[idx] <- predict(m3, newdata = test, type = "fitted")
}

# Fit meta-model (stacking)
meta_model <- glm(obs ~ p1 + p2 + p3, data = oof_preds, family = binomial)
meta_prob <- predict(meta_model, type = "response")


# optimal preds

preds_meta <- data.frame(1, oof_preds$obs, meta_prob)
optimal.thresholds(preds_meta) # 0.41

preds_m1 <- data.frame(1, oof_preds$obs, oof_preds$p1)
optimal.thresholds(preds_m1) # 0.49

preds_m2 <- data.frame(1, oof_preds$obs, oof_preds$p2)
optimal.thresholds(preds_m2) # 0.55

preds_m3 <- data.frame(1, oof_preds$obs, oof_preds$p3)
optimal.thresholds(preds_m3) # 0.41


meta_class <- ifelse(meta_prob > 0.41, 1, 0)

# Evaluation
conf <- confusionMatrix(factor(meta_class), factor(oof_preds$obs), positive = "1")
auc <- auc(oof_preds$obs, meta_prob)
brier <- mean((meta_prob - oof_preds$obs)^2)

cat("Stacked Ensemble AUC:", round(auc, 3), "\n")
cat("Brier Score:", round(brier, 3), "\n")
print(conf)


##  Evaluation individual models
## M1
confusionMatrix(factor(ifelse(oof_preds$p1 > 0.49, 1, 0)), factor(oof_preds$obs), positive = "1")
confusionMatrix(factor(ifelse(oof_preds$p2 > 0.55, 1, 0)), factor(oof_preds$obs), positive = "1")
confusionMatrix(factor(ifelse(oof_preds$p3 > 0.41, 1, 0)), factor(oof_preds$obs), positive = "1")



```

```{r}
library(rms)
library(caret)

set.seed(123)

# Definir os folds
folds <- createFolds(df_predictors$epidemic, k = 10, returnTrain = FALSE)

# Inicializar dataframe para armazenar predições
n <- nrow(df_predictors)
oof_preds <- data.frame(
  p1 = rep(NA, n),
  p2 = rep(NA, n),
  p3 = rep(NA, n),
  obs = df_predictors$epidemic
)

# Loop da validação cruzada manual
for (i in seq_along(folds)) {
  test_idx <- folds[[i]]
  train_idx <- setdiff(seq_len(n), test_idx)
  
  train_data <- df_predictors[train_idx, ]
  test_data  <- df_predictors[test_idx, ]
  
  # Modelo 1
  m1 <- lrm(factor(epidemic) ~ rcs(tmin, 3) + rcs(rh, 4), data = train_data, x = TRUE, y = TRUE)
  oof_preds$p1[test_idx] <- predict(m1, newdata = test_data, type = "fitted")
  
  # Modelo 2
  m2 <- lrm(factor(epidemic) ~ rcs(rh, 4) + rcs(dew, 3), 
                  data = df_predictors, x = TRUE, y = TRUE)
  oof_preds$p2[test_idx] <- predict(m2, newdata = test_data, type = "fitted")
  
  # Modelo 3
  m3 <- lrm(factor(epidemic) ~ rcs(tmin, 3) + prec2, 
                  data = df_predictors, x = TRUE, y = TRUE)
  oof_preds$p3[test_idx] <- predict(m3, newdata = test_data, type = "fitted")
}

# Ensemble via soft voting (unweighted)
oof_preds$ensemble_unw <- rowMeans(oof_preds[, c("p1", "p2", "p3")], na.rm = TRUE)

# Opcional: transformar para classe usando limiar de 0.5
oof_preds$class_p1 <- ifelse(oof_preds$p1 > 0.5, 1, 0)
oof_preds$class_p2 <- ifelse(oof_preds$p2 > 0.5, 1, 0)
oof_preds$class_p3 <- ifelse(oof_preds$p3 > 0.5, 1, 0)
oof_preds$class_ensemble_unw <- ifelse(oof_preds$ensemble_unw > 0.5, 1, 0)

```

# Figuras

```{r}
library(tidyverse)
library(ggthemes)
library(grid)
library(gridExtra)
library(patchwork)

# tidyfun is currently not on CRAN. You can install the development version from GitHub with:
# # install.packages("pak")
#pak::pak("tidyfun/tidyfun")
library(tidyfun)
# my modifications to the geom-spaghetti function (updated ggplot linewidth instead of size):
source(here::here("geom-spaghetti.R"))

# theme_half_open is part of the cowplot themes
# theme_set(theme_half_open(font_size = 12))
```

## Função

```{r}
itp.curves <- function(data, variable, sig_days = NULL, .ylab = NULL) {
  var_sym <- rlang::enquo(variable)
  
  p <- suppressMessages(
    data %>%
      dplyr::select(study, days, epidemic, !!var_sym) %>%
      tf_nest(!!var_sym, .id = study, .arg = days) %>%
      dplyr::group_by(epidemic) %>%
      dplyr::summarize(var_mean = mean(!!var_sym)) %>%
      dplyr::mutate(smooth_mean = tfb(var_mean)) %>%
      ggplot(aes(tf = smooth_mean, color = factor(epidemic))) +
      geom_spaghetti(linewidth = 2, alpha = 1) +
      scale_x_continuous(breaks = seq(-28, 28, by = 4)) +
      geom_vline(xintercept = 0, color = "gray", linetype = "dashed") +
      ggthemes::scale_color_excel_new(labels = c("Non-epidemic", "Epidemic")) +
      theme_bw() +
      labs(x = "Days relative to event",
           y = .ylab,
           color = "Epidemic status") +
      theme(axis.title.y = element_text(size = 12),
            axis.title.x = element_text(size = 12),
            axis.text.x = element_text(size = 9),
            axis.text.y = element_text(size = 9),
            legend.position = "bottom")
  )
  
  # Adiciona o sombreado dos dias significativos (se houver)
  if (!is.null(sig_days)) {
    for (d in sig_days) {
      p <- p + annotate("rect", xmin = d - 0.5, xmax = d + 0.5, ymin = -Inf, ymax = Inf,
                        fill = "gray40", alpha = 0.3)
    }
  }
  
  return(p)
}
```

### RH5_10

```{r}
itp_rh <- c(5, 6, 7, 8, 9, 10)

rh_curves <- itp.curves(data, RH2M, sig_days  = itp_rh, .ylab = "Relative humidity (%)")
```

### Tmin2_10

```{r}
itp_tmin <- 2:10

tmin_curves <- itp.curves(data, T2M_MIN, sig_days = itp_tmin, .ylab = "Min Temperature (°C)")
```

### Tdew4_10

```{r}
itp_tdew <- 4:10

tdew_curves <- itp.curves(data_nasa, T2MDEW, sig_days = itp_tdew, .ylab = "Dew point (°C)")
```

### Prec6_10

```{r}
itp_prec <- 6:10

prec_curves <- itp.curves(data_nasa, PRECTOTCORR, sig_days = itp_prec, .ylab = "Precipitation (mm)")
```

### boxplots 2

```{r}
p_tmin1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), tmin, color = factor(epidemic))) +
  geom_boxplot(fill = NA, linewidth = 0.9) +  # fill = NA para não colorir interior
  labs(y = "Tmin<sub>2_10</sub> (°C)", x = "Epidemic") +
  ggthemes::scale_color_excel_new(labels = c("Non-epidemic", "Epidemic")) +
  theme_bw()+
  theme(
    axis.title.y = element_markdown(size = 12),  # habilita Markdown no eixo Y
    axis.title.x = element_text(size = 12),
    legend.position = "none",            # opcional
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
    )
 
p_dew1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), dew, color = factor(epidemic)))+
  geom_boxplot(fill = NA, linewidth = 0.9) +
  labs(y = "Tdew<sub>4_10</sub> (°C)", x = "Epidemic")+
  ggthemes::scale_color_excel_new(labels = c("Non-epidemic", "Epidemic")) +
  theme_bw()+
  theme(
    axis.title.y = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.x = element_text(size = 12),
    legend.position = "none",
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )

p_rh1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), rh, color = factor(epidemic)))+
  geom_boxplot(fill = NA, linewidth = 0.9)+
  labs(x = "Epidemic", y = "RH<sub>5_10</sub> (%)")+
  ggthemes::scale_color_excel_new(labels = c("Non-epidemic", "Epidemic")) +
  theme_bw()+
  theme(
    axis.title.y = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.x = element_text(size = 12),
    legend.position = "none",
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
      )

p_prec1 <- df_predictors |> 
  ggplot(aes(factor(epidemic), prec2, color = factor(epidemic)))+
  geom_boxplot(fill = NA, linewidth = 0.9)+
  ggthemes::scale_color_excel_new(labels = c("Non-epidemic", "Epidemic")) +
  theme_bw()+
  labs(x = "Epidemic", y = "PREC<sub>6_10</sub> (mm)")+
    theme(
    axis.title.y = element_markdown(size = 12),  # enable Markdown in Y-axis label
    axis.title.x = element_text(size = 12),
    legend.position = "none",
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
    )
```

### patchwork

```{r}
(tmin_curves | p_tmin1) /
(rh_curves | p_rh1) /
(tdew_curves | p_dew1) /
(prec_curves | p_prec1) +
  plot_layout(guides = "collect") &  # coleta todas as legendas em uma só
  theme(legend.position = "bottom") &  # define a posição da legenda
    plot_annotation(tag_levels = "A")

  
#ggsave("imagem_1.png", dpi = 300, bg = "white", width = 8, height = 11)
```

## Histograma

```{r}
# 1. Probabilidades previstas de cada modelo
df_preds <- data.frame(
  epidemic = df_predictors$epidemic,  # variável resposta observada
  LM1   = predict(models$model1, type = "fitted"),
  LM2   = predict(models$model2, type = "fitted"),
  LM3   = predict(models$model3, type = "fitted"),
  UNW   = (predict(models$model1, type = "fitted") + predict(models$model2, type = "fitted") + predict(models$model3, type = "fitted")) / 3,
  WGT   = 0.102 * predict(models$model1, type = "fitted") + 0.43  * predict(models$model2, type = "fitted") + 0.46  * predict(models$model3, type = "fitted"),
  STACK = predict(meta_model, type = "response")
)

# 2. Colocar em formato longo
df_long <- df_preds %>%
  pivot_longer(
    cols = -epidemic,
    names_to = "model",
    values_to = "prob"
  )

df_long <- df_long %>%
  mutate(epidemic_f = factor(epidemic, levels = c(0, 1),
                             labels = c("Non-epidemic", "Epidemic")))

# 3. Histograma das probabilidades previstas
ggplot(df_long, aes(x = prob, fill = factor(epidemic), color = factor(epidemic))) +
  geom_histogram(bins = 20, linewidth = 0.8, alpha = 0.8, position = "identity") +
  facet_grid(model ~ epidemic_f) +
  labs(x = "Model-fitted probability",
       y = "Count") +
  scale_fill_manual(values = c("0" = "#4970b5", "1" = "#ed7d31"),
                    labels = c("Non-epidemic", "Epidemic")) +
  scale_color_manual(values = c("0" = "#4970b5", "1" = "#ed7d31")) +
  theme_bw() +
  theme(
    axis.title.y = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    legend.position = "none",
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 9)
  )


#ggsave("imagem_2.png", dpi = 600, bg = "white", width = 8, height = 10)
```
